import { useRef, useEffect, useMemo, useState, useCallback } from "react";
import { useNavigate } from "react-router-dom";
import Webcam from "react-webcam";
import styles from "./CameraCapture.module.css"
import useCameraReady from "../../hooks/useCameraReady";
import { addImage } from "../../shared/api/images-api";

const CameraCapture = () => {
    const navigate = useNavigate();
    const webcamRef = useRef(null);
    const [hasFourMarkers, setHasFourMarkers] = useState(false);
    const [isProcessing, setIsProcessing] = useState(false);
    const detectionIntervalRef = useRef(null);
    const isDetectingRef = useRef(false);
    const rafIdRef = useRef(null);
    const hasAutoCapturedRef = useRef(false); 

    const isReady = useCameraReady(webcamRef);

    const videoConstraints = useMemo(() => ({
        facingMode: "environment",
        width: { ideal: 1920 },
        height: { ideal: 1080 },
    }), []);

    // Image capture handler - sending to backend
    const handleCapture = useCallback(async (blob) => {
        try {
            console.log("ðŸ“¤ ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð½Ð° Ð±ÑÐºÐµÐ½Ð´...");
            
            // Go to the processing page IMMEDIATELY
            navigate("/camera-processing", { 
                state: { 
                    imageBlob: blob
                } 
            });
            
            // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð½Ð° Ð±ÑÐºÐµÐ½Ð´ Ð² Ñ„Ð¾Ð½Ðµ
            const formData = new FormData();
            formData.append('image', blob, 'cropped-image.jpg');
            
            const result = await addImage(formData);
            
            console.log("âœ… ÐžÑ‚Ð²ÐµÑ‚ Ð¾Ñ‚ Ð±ÑÐºÐµÐ½Ð´Ð°:", result);
            
            // Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ Ð½Ð° ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ðµ CameraProcessingPage
            
        } catch (error) {
            console.error("âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð½Ð° Ð±ÑÐºÐµÐ½Ð´:", error);
            alert("ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑÐ½Ð¾Ð²Ð°.");
            setIsProcessing(false);
            hasAutoCapturedRef.current = false; // Ð¡Ð±Ñ€Ð°ÑÑ‹Ð²Ð°ÐµÐ¼ Ñ„Ð»Ð°Ð³ Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ
            
            // Ð’Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð´ÐµÑ‚ÐµÐºÑ†Ð¸ÑŽ Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ
            if (isReady && window.cv) {
                detectionIntervalRef.current = setInterval(detectMarkers, 400);
            }
        }
    }, [navigate, isReady]);

    // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð²Ñ‹Ñ…Ð¾Ð´Ð°
    const handleExit = useCallback(() => {
        const video = webcamRef.current?.video;
        video?.srcObject?.getTracks().forEach(track => track.stop());
        navigate("/camera-access");
    }, [navigate]);

    // Ð”ÐµÑ‚ÐµÐºÑ†Ð¸Ñ Ð¼Ð°Ñ€ÐºÐµÑ€Ð¾Ð² (Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ)
    const detectMarkers = useCallback(() => {
        if (isDetectingRef.current || !webcamRef.current || !window.cv) return;

        const video = webcamRef.current.video;
        if (!video || video.readyState !== video.HAVE_ENOUGH_DATA) return;

        isDetectingRef.current = true;

        rafIdRef.current = requestAnimationFrame(() => {
            try {
                const cv = window.cv;

                const tempCanvas = document.createElement('canvas');
                const scale = 0.3;
                tempCanvas.width = video.videoWidth * scale;
                tempCanvas.height = video.videoHeight * scale;
                const ctx = tempCanvas.getContext('2d');
                ctx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);

                const img = cv.imread(tempCanvas);

                const dictionary = cv.getPredefinedDictionary(cv.DICT_4X4_50);
                const detectorParams = new cv.aruco_DetectorParameters();
                const refineParams = new cv.aruco_RefineParameters(10, 3, true);
                const detector = new cv.aruco_ArucoDetector(dictionary, detectorParams, refineParams);

                const corners = new cv.MatVector();
                const ids = new cv.Mat();
                detector.detectMarkers(img, corners, ids);

                const cornerIds = [0, 1, 3, 2];
                let foundCount = 0;

                for (let i = 0; i < ids.rows; i++) {
                    const markerId = ids.intAt(i, 0);
                    if (cornerIds.includes(markerId)) {
                        foundCount++;
                    }
                }

                const allFound = foundCount === 4;
                setHasFourMarkers(allFound);

                // ðŸŽ¯ ÐÐ’Ð¢ÐžÐœÐÐ¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð™ Ð—ÐÐ¥Ð’ÐÐ¢ Ð¿Ñ€Ð¸ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ð¸ Ð²ÑÐµÑ… 4 Ð¼Ð°Ñ€ÐºÐµÑ€Ð¾Ð²
                if (allFound && !hasAutoCapturedRef.current && !isProcessing) {
                    console.log("ðŸŽ¯ Ð’ÑÐµ 4 Ð¼Ð°Ñ€ÐºÐµÑ€Ð° Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹! ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð·Ð°Ñ…Ð²Ð°Ñ‚...");
                    hasAutoCapturedRef.current = true; // Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ñ„Ð»Ð°Ð³
                    
                    // Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÑƒÑŽ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÑƒ Ð´Ð»Ñ ÑÑ‚Ð°Ð±Ð¸Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸
                    setTimeout(() => {
                        captureAndCrop();
                    }, 500);
                }

                img.delete();
                corners.delete();
                ids.delete();
                detector.delete();
                detectorParams.delete();
                refineParams.delete();
                dictionary.delete();
            } catch (error) {
                console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð´ÐµÑ‚ÐµÐºÑ†Ð¸Ð¸ Ð¼Ð°Ñ€ÐºÐµÑ€Ð¾Ð²:', error);
            } finally {
                isDetectingRef.current = false;
            }
        });
    }, [isProcessing]);

    // ÐžÐ±Ñ€ÐµÐ·ÐºÐ° Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    const captureAndCrop = useCallback(async () => {
        if (!webcamRef.current || !window.cv || isProcessing) return;

        setIsProcessing(true);

        if (detectionIntervalRef.current) {
            clearInterval(detectionIntervalRef.current);
        }

        setTimeout(async () => {
            try {
                const video = webcamRef.current.video;
                const cv = window.cv;

                const tempCanvas = document.createElement('canvas');
                tempCanvas.width = video.videoWidth;
                tempCanvas.height = video.videoHeight;
                const ctx = tempCanvas.getContext('2d');
                ctx.drawImage(video, 0, 0);

                let img = cv.imread(tempCanvas);

                const dictionary = cv.getPredefinedDictionary(cv.DICT_4X4_50);
                const detectorParams = new cv.aruco_DetectorParameters();
                const refineParams = new cv.aruco_RefineParameters(10, 3, true);
                const detector = new cv.aruco_ArucoDetector(dictionary, detectorParams, refineParams);

                const corners = new cv.MatVector();
                const ids = new cv.Mat();
                detector.detectMarkers(img, corners, ids);

                if (corners.size() < 4) {
                    alert('ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ 4 Ð¼Ð°Ñ€ÐºÐµÑ€Ð°!');
                    img.delete();
                    corners.delete();
                    ids.delete();
                    detector.delete();
                    detectorParams.delete();
                    refineParams.delete();
                    dictionary.delete();
                    setIsProcessing(false);
                    hasAutoCapturedRef.current = false;
                    if (isReady && window.cv) {
                        detectionIntervalRef.current = setInterval(detectMarkers, 400);
                    }
                    return;
                }

                const cornerIds = [0, 1, 3, 2];
                const markerCorners = {};

                for (let i = 0; i < ids.rows; i++) {
                    const markerId = ids.intAt(i, 0);

                    if (cornerIds.includes(markerId)) {
                        const corner = corners.get(i);

                        markerCorners[markerId] = {
                            topLeft: { x: corner.floatAt(0, 0), y: corner.floatAt(0, 1) },
                            topRight: { x: corner.floatAt(0, 2), y: corner.floatAt(0, 3) },
                            bottomRight: { x: corner.floatAt(0, 4), y: corner.floatAt(0, 5) },
                            bottomLeft: { x: corner.floatAt(0, 6), y: corner.floatAt(0, 7) }
                        };
                    }
                }

                if (Object.keys(markerCorners).length < 4) {
                    alert('ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð¼ÐµÐ½ÑŒÑˆÐµ 4 ÑƒÐ³Ð»Ð¾Ð²Ñ‹Ñ… Ð¼Ð°Ñ€ÐºÐµÑ€Ð¾Ð²!');
                    img.delete();
                    corners.delete();
                    ids.delete();
                    detector.delete();
                    detectorParams.delete();
                    refineParams.delete();
                    dictionary.delete();
                    setIsProcessing(false);
                    hasAutoCapturedRef.current = false;
                    if (isReady && window.cv) {
                        detectionIntervalRef.current = setInterval(detectMarkers, 400);
                    }
                    return;
                }

                const topLeftMarker = markerCorners[cornerIds[0]];
                const topRightMarker = markerCorners[cornerIds[1]];
                const bottomRightMarker = markerCorners[cornerIds[2]];
                const bottomLeftMarker = markerCorners[cornerIds[3]];

                const offset = {
                    top: 10,
                    bottom: 5,
                    left: 7,
                    right: 7
                };

                const offsetPoint = (point, direction, distance) => {
                    const len = Math.hypot(direction.x, direction.y);
                    if (len === 0) return point;

                    const normalized = { x: direction.x / len, y: direction.y / len };
                    return {
                        x: point.x + normalized.x * distance,
                        y: point.y + normalized.y * distance
                    };
                };

                const topLeftDir = {
                    x: bottomLeftMarker.topLeft.x - topLeftMarker.bottomLeft.x,
                    y: bottomLeftMarker.topLeft.y - topLeftMarker.bottomLeft.y
                };
                const topDir = {
                    x: topRightMarker.bottomRight.x - topLeftMarker.bottomLeft.x,
                    y: topRightMarker.bottomRight.y - topLeftMarker.bottomLeft.y
                };
                const topRightDir = {
                    x: bottomRightMarker.topRight.x - topRightMarker.bottomRight.x,
                    y: bottomRightMarker.topRight.y - topRightMarker.bottomRight.y
                };
                const bottomDir = {
                    x: bottomLeftMarker.topLeft.x - bottomRightMarker.topRight.x,
                    y: bottomLeftMarker.topLeft.y - bottomRightMarker.topRight.y
                };

                let pt1 = offsetPoint(topLeftMarker.bottomLeft, topLeftDir, offset.top);
                pt1 = offsetPoint(pt1, { x: -topDir.x, y: -topDir.y }, offset.left);

                let pt2 = offsetPoint(topRightMarker.bottomRight, topRightDir, offset.top);
                pt2 = offsetPoint(pt2, topDir, offset.right);

                let pt3 = offsetPoint(bottomRightMarker.topRight, topRightDir, -offset.bottom);
                pt3 = offsetPoint(pt3, { x: -bottomDir.x, y: -bottomDir.y }, offset.right);

                let pt4 = offsetPoint(bottomLeftMarker.topLeft, topLeftDir, -offset.bottom);
                pt4 = offsetPoint(pt4, bottomDir, offset.left);

                const srcPoints = cv.matFromArray(4, 1, cv.CV_32FC2, [
                    pt1.x, pt1.y,
                    pt2.x, pt2.y,
                    pt3.x, pt3.y,
                    pt4.x, pt4.y
                ]);

                const width = Math.max(
                    Math.hypot(pt2.x - pt1.x, pt2.y - pt1.y),
                    Math.hypot(pt3.x - pt4.x, pt3.y - pt4.y)
                );

                const height = Math.max(
                    Math.hypot(pt4.x - pt1.x, pt4.y - pt1.y),
                    Math.hypot(pt3.x - pt2.x, pt3.y - pt2.y)
                );

                const dstPoints = cv.matFromArray(4, 1, cv.CV_32FC2, [
                    0, 0,
                    width, 0,
                    width, height,
                    0, height
                ]);

                const M = cv.getPerspectiveTransform(srcPoints, dstPoints);

                const warped = new cv.Mat();
                const dsize = new cv.Size(width, height);
                cv.warpPerspective(img, warped, M, dsize);

                const outputCanvas = document.createElement('canvas');
                cv.imshow(outputCanvas, warped);

                outputCanvas.toBlob(async (blob) => {
                    if (blob) {
                        await handleCapture(blob);
                    }
                }, 'image/jpeg', 0.95);

                img.delete();
                corners.delete();
                ids.delete();
                detector.delete();
                detectorParams.delete();
                refineParams.delete();
                dictionary.delete();
                srcPoints.delete();
                dstPoints.delete();
                M.delete();
                warped.delete();

            } catch (error) {
                console.error('ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ:', error);
                alert('ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ');
                setIsProcessing(false);
                hasAutoCapturedRef.current = false;
                if (isReady && window.cv) {
                    detectionIntervalRef.current = setInterval(detectMarkers, 400);
                }
            }
        }, 0);
    }, [isProcessing, handleCapture, isReady, detectMarkers]);

    useEffect(() => {
        if (isReady && window.cv) {
            detectionIntervalRef.current = setInterval(detectMarkers, 400);
        }

        return () => {
            if (detectionIntervalRef.current) {
                clearInterval(detectionIntervalRef.current);
            }
            if (rafIdRef.current) {
                cancelAnimationFrame(rafIdRef.current);
            }
        };
    }, [isReady, detectMarkers]);

    useEffect(() => {
        if (hasFourMarkers && navigator.vibrate) {
            navigator.vibrate(80);
        }
    }, [hasFourMarkers]);

    useEffect(() => {
        return () => {
            const video = webcamRef.current?.video;
            video?.srcObject?.getTracks().forEach(track => track.stop());
        };
    }, []);

    if (!window.cv || !cv.Mat) {
        return <div>Loading OpenCV...</div>;
    }

    return (
        <div className={styles.cameraContainer}>
            {/* <div className={`${styles.overlayBackground} ${hasFourMarkers ? styles.focused : ""}`}></div> */}

            <Webcam
                ref={webcamRef}
                audio={false}
                screenshotFormat="image/png"
                videoConstraints={videoConstraints}
                className={`${styles.webcamVideo} ${isReady ? styles.show : ""}`}
                onUserMediaError={err => {
                    console.error("Camera error:", err);
                    alert("Unable to start camera. Check permissions.");
                    handleExit();
                }}
                playsInline
            />

            <div className={`${styles.viewfinder} ${hasFourMarkers ? styles.detected : ""}`}>
                <div className={styles["bottom-left"]}></div>
                <div className={styles["bottom-right"]}></div>
            </div>

            <div className={styles.hintMessage}>
                <p className={styles.hintMessageText}>
                    Align the test card in the frame
                </p>
            </div>
        </div>
    );
};

export default CameraCapture;


